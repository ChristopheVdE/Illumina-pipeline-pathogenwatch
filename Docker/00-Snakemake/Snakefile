############################################################################################################
#NAME:  SNAKEMAKE
#AUTHOR: Christophe Van den Eynde
#RUNNING: Salmonella t. pipeline for Illumina reads
#USAGE: $snakemake
############################################################################################################

#SNAKEMAKE RUN PREPARATION==================================================================================
# GET INFO FROM HOST----------------------------------------------------------------------------------------
env = open("/home/Pipeline/environment.txt","r")
for line in env.readlines():
    # GET LOCATIONS-----------------------------------------------------------------------------------------
    if "Results_m=" in line:
        Results_m = line.replace("Results_m=",'').replace('\n','')
env.close()
#-----------------------------------------------------------------------------------------------------------

#GET SAMPLE IDS---------------------------------------------------------------------------------------------
ids = []
samples = open("/home/Pipeline/sampleList.txt","r")
for line in samples.readlines():
    ids.append(line.replace('\n',''))
samples.close()
#-----------------------------------------------------------------------------------------------------------
#===========================================================================================================

#SNAKEMAKE RUN==============================================================================================
#-----------------------------------------------------------------------------------------------------------
# Master rule, controls all other rule executions

rule all:                                                                       
    input:
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_MultiQC/multiqc_report.html",id=ids),                            
        expand("/home/Pipeline/{id}/03_QC-Trimmomatic_Paired/QC_MultiQC/multiqc_report.html",id=ids),                       
        expand("/home/Pipeline/{id}/04_SPAdes/dataset.info",id=ids)                                             
    message:
        "Analysis done, results can be found in {Results_m}"

#-----------------------------------------------------------------------------------------------------------
# Pipeline step1: copy/move files from raw data folder to 'Sample_id/00_Rawdata/' in the analysis-results folder
# executed in get_environment.py

#-----------------------------------------------------------------------------------------------------------
# Pipeline step2: running fastqc on the raw-data in the current-analysis folder

rule fastqc_raw:
    input:
        expand("/home/Pipeline/{id}/00_Rawdata/{id}_L001_R1_001.fastq.gz",id=ids),  #the rawdata (output copy_rawdata rule)
        expand("/home/Pipeline/{id}/00_Rawdata/{id}_L001_R2_001.fastq.gz",id=ids)   #the rawdata (output copy_rawdata rule)
    output:
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_FastQC/{id}_L001_R1_001_fastqc.html",id=ids),
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_FastQC/{id}_L001_R2_001_fastqc.html",id=ids)
    message:
        "Analyzing raw-data with FastQC using Docker-container fastqc:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name fastqc_raw \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/fastqc:v2.2_stable \
        /home/Scripts/QC01_fastqcRawData.sh'

#-----------------------------------------------------------------------------------------------------------
# Pipeline step3: running multiqc on the raw-data in the current-analysis folder

rule multiqc_raw:
    input:
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_FastQC/{id}_L001_R1_001_fastqc.html",id=ids),    #output fastqc rawdata
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_FastQC/{id}_L001_R2_001_fastqc.html",id=ids)     #output fastqc rawdata
    output:
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_MultiQC/multiqc_report.html",id=ids)             #Results MultiQC for each sample separately
    message:
        "Analyzing raw-data with MultiQC using Docker-container multiqc:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name multiqc_raw \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/multiqc:v2.2_stable \
        /home/Scripts/QC01_multiqc_raw.sh'

#-----------------------------------------------------------------------------------------------------------
# Pipeline step4: Trimming

rule Trimming:
    input:
        expand("/home/Pipeline/{id}/00_Rawdata/{id}_L001_R1_001.fastq.gz",id=ids),          #the rawdata (output copy_rawdata rule)
        expand("/home/Pipeline/{id}/00_Rawdata/{id}_L001_R2_001.fastq.gz",id=ids),          #the rawdata (output copy_rawdata rule)
        expand("/home/Pipeline/{id}/01_QC-Rawdata/QC_MultiQC/multiqc_report.html",id=ids)   #output multiqc raw (required so that the tasks don't run simultaniously and their outpur gets mixed in the terminal)
    output:
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R1_001_P.fastq.gz",id=ids),
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R2_001_U.fastq.gz",id=ids)
    message:
        "Trimming raw-data with Trimmomatic v0.39 using Docker-container trimmomatic:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name trimmomatic \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/trimmomatic:v2.2_stable \
        /home/Scripts/02_runTrimmomatic.sh'

#-----------------------------------------------------------------------------------------------------------
# Pipeline step5: FastQC trimmed data (paired reads only)

rule fastqc_trimmed:
    input:
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R1_001_P.fastq.gz",id=ids), #output trimmomatic
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R2_001_U.fastq.gz",id=ids)  #output trimmomatic
    output:
        expand("/home/Pipeline/{id}/03_QC-Trimmomatic_Paired/QC_FastQC/{id}_L001_R1_001_P_fastqc.html",id=ids)
    message:
        "Analyzing trimmed-data with FastQC using Docker-container fastqc:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name fastqc_trim \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/fastqc:v2.2_stable \
        /home/Scripts/QC02_fastqcTrimmomatic.sh'

#-----------------------------------------------------------------------------------------------------------
# Pipeline step6: MultiQC trimmed data (paired reads only) 

rule multiqc_trimmed:
    input:
        expand("/home/Pipeline/{id}/03_QC-Trimmomatic_Paired/QC_FastQC/{id}_L001_R1_001_P_fastqc.html",id=ids)      #output fastqc trimmed data
    output:
        expand("/home/Pipeline/{id}/03_QC-Trimmomatic_Paired/QC_MultiQC/multiqc_report.html",id=ids)
    message:
        "Analyzing trimmed-data with MultiQC using Docker-container multiqc:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name multiqc_trim \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/multiqc:v2.2_stable \
        /home/Scripts/QC02_multiqcTrimmomatic.sh'

#-----------------------------------------------------------------------------------------------------------
# Pipeline step7: SPAdes

rule Spades_InputPathogenwatch:
    input:
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R1_001_P.fastq.gz",id=ids),                # output trimming
        expand("/home/Pipeline/{id}/02_Trimmomatic/{id}_L001_R2_001_U.fastq.gz",id=ids),                # output trimming
        expand("/home/Pipeline/{id}/03_QC-Trimmomatic_Paired/QC_MultiQC/multiqc_report.html",id=ids)    # output multiqc-trimmed
    output:
        expand("/home/Pipeline/{id}/04_SPAdes/dataset.info",id=ids),
        directory(expand("/home/Pipeline/{id}/05_inputPathogenWatch",id=ids))
    message:
        "assembling genome from trimmed-data with SPAdes v3.13.1 using Docker-container SPAdes:v2.2_stable"
    shell:
        'docker run -it --rm \
        --name spades \
        -v "{Results_m}:/home/Pipeline/" \
        christophevde/spades:v2.2_stable \
        /home/Scripts/03_spades.sh'

#-----------------------------------------------------------------------------------------------------------
#===========================================================================================================